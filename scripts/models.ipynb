{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.optimizers import SGD  # Stochastic Gradient Descent\n",
    "from tensorflow.keras.optimizers import Adam  # Adam\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the preprocessed data\n",
    "X_train=pd.read_csv('C:/Users/sarho66/OneDrive - Linköpings universitet/mimic-iii/data/X_train_imputed.csv')\n",
    "y_train=pd.read_csv('C:/Users/sarho66/OneDrive - Linköpings universitet/mimic-iii/data/y_train.csv')\n",
    "X_test=pd.read_csv('C:/Users/sarho66/OneDrive - Linköpings universitet/mimic-iii/data/X_test_imputed.csv')\n",
    "y_test=pd.read_csv('C:/Users/sarho66/OneDrive - Linköpings universitet/mimic-iii/data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a single-column DataFrame to a Series\n",
    "y_train = y_train.squeeze()  # If y_train is a DataFrame with one column\n",
    "y_test = y_test.squeeze()  # If y_test is a DataFrame with one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train==1].shape[0]/y_train.shape[0]*100\n",
    "y_test[y_test==1].shape[0]/y_test.shape[0]*100\n",
    "print(f\" Dead percentage in Train: {y_train[y_train==1].shape[0]/y_train.shape[0]*100:.2f}%, \\n Dead percentage in Test: {y_test[y_test==1].shape[0]/y_test.shape[0]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model\n",
    "\n",
    "tf.random.set_seed(123)\n",
    "model_1 = Sequential([\n",
    "    # First hidden layer (acts as the input layer with input_shape defined) with 64 neurons\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    # Second hidden layer with 32 neurons\n",
    "    Dense(32, activation='relu'),\n",
    "    # Output layer with 1 neuron for binary classification\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential([\n",
    "    # First hidden layer (acts as the input layer with input_shape defined) with 64 neurons\n",
    "    Dense(1, activation='sigmoid', input_shape=(X_train.shape[1],)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Define a small epsilon value\n",
    "    epsilon = 1e-7\n",
    "    \n",
    "    # Add epsilon to y_pred to ensure it's never exactly 0 or 1\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "    \n",
    "    # Log the minimum values in y_pred to check for zeros or near-zero values\n",
    "    tf.print(\"Min value in y_pred:\", tf.reduce_min(y_pred))\n",
    "    tf.print(\"Min value in y_true:\", tf.reduce_min(y_true))\n",
    "\n",
    "    # Compute the loss as usual\n",
    "    loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "    # Check if the loss becomes NaN\n",
    "    loss_is_nan = tf.reduce_any(tf.math.is_nan(loss))\n",
    "    if loss_is_nan:\n",
    "        tf.print(\"NaN detected in loss\")\n",
    "\n",
    "    return loss\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) \n",
    "\n",
    "model_1.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "history=model_1.fit(X_train,y_train,epochs=150,verbose=1, validation_split=0.2)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'history' is the object returned by the 'fit' method of your model\n",
    "# and contains the training history. Remember, indexing starts at 0,\n",
    "# so 'after 5 epochs' means starting from index 5 (i.e., epoch 6 onwards).\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plotting training & validation accuracy values starting after epoch 5\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])  # Start from index 5 to skip first 5 epochs\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plotting training & validation loss values starting after epoch 5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of the model\n",
    "test_loss, test_acc= model_1.evaluate(X_test, y_test)\n",
    "print(f\"Test Acuuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}